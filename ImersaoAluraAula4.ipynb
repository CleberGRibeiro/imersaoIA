{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPFlc/M5oaPNlRmArMY6AxA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CleberGRibeiro/imersaoIA/blob/main/ImersaoAluraAula4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kEe3XJoJjCqY"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalando o SDK do google"
      ],
      "metadata": {
        "id": "sbE2O-VkjFpk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "NYKdhRy7jNXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the Python SDK\n",
        "import google.generativeai as genai\n",
        "\n",
        "# para não deixar visível a string KEY que é única do usuário Google\n",
        "# deve-se utilizar o código abaixo para fazer um link entre a chamada de\n",
        "# usuário \"USERDATA\" e o Notebook access que são os parâmetros informados dentro\n",
        "# do Colab no menu ao lado esquerdo\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('chaveSecreta')\n",
        "GOOGLE_API_KEY= api_key\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "4bXv9Y09joZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Listar os modelos disponiveis\n"
      ],
      "metadata": {
        "id": "GSMG7f7UjyI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for m in genai.list_models():\n",
        "  if 'generateContent' in m.supported_generation_methods:\n",
        "   print(m.name)"
      ],
      "metadata": {
        "id": "JeO4p6GLj2uA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generation_config = {\n",
        "    \"candidate_count\" : 1,\n",
        "    \"temperature\": 0.5\n",
        "}"
      ],
      "metadata": {
        "id": "-OorkhIDpPYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nível de bloqueios para conteúdos assédio, ódio, sexual e perigoso, o termo \"BLOCK_NONE\" não bloqueia nada e se usar o \"BLOCK_SOME\"."
      ],
      "metadata": {
        "id": "gTFTKMfHrBu1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "safety_settings = {\n",
        "    \"HARASSMENT\" : \"BLOCK_NONE\",\n",
        "    \"HATE\" : \"BLOCK_NONE\",\n",
        "    \"SEXUAL\" : \"BLOCK_NONE\",\n",
        "    \"DANGEROUS\" : \"BLOCK_NONE\"\n",
        "}"
      ],
      "metadata": {
        "id": "0MBH5CyFp5sT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui é criada uma instancia com os parâmetros escolhidos à partir dos dados listados acima: modelolo da IA, parâmetros e níveis de segurança das respostas."
      ],
      "metadata": {
        "id": "qnBBltfiun1T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicializando o modelo\n"
      ],
      "metadata": {
        "id": "UzPoGyLPsVeX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name = \"gemini-1.0-pro\",\n",
        "                              generation_config = generation_config,\n",
        "                              safety_settings = safety_settings)"
      ],
      "metadata": {
        "id": "J4DnP6OZsZvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui é instanciada a chamada e sua resposta para a IA.\n",
        "\n",
        "IMPORTANTE:\n",
        "se no print não for colocado \"response.text\" e sim somente \"response\" a IA responderá em Json."
      ],
      "metadata": {
        "id": "N_GPDwBzvJ11"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#response = model.generate_content(\"Qual a cor do cavalo branco do napoleão?\")\n",
        "#print (response.text)\n"
      ],
      "metadata": {
        "id": "sw-JnBJFvJc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criando um chatBot\n"
      ],
      "metadata": {
        "id": "Em-oJHNyyOvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat(history = [])"
      ],
      "metadata": {
        "id": "6_MnvfVuyRzl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criando uma entrada de dados."
      ],
      "metadata": {
        "id": "nTgQ6BlK9lg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = input(\"Entre com a sua pergunta: \")\n",
        "\n",
        "while prompt != \"fim\":\n",
        "  response = chat.send_message(prompt)\n",
        "  print (\"Resposta: \", response.text, \"\\n\")\n",
        "  prompt = input(\"Entre com a sua pergunta: \")"
      ],
      "metadata": {
        "id": "Hl4eZnty9cQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para melhorar a visualização do teste.\n"
      ],
      "metadata": {
        "id": "3YSprZgD_wuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import textwrap\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "def to_markdown(text):\n",
        "  text = text.replace('*',' ')\n",
        "  return Markdown(textwrap.indent(text, '>', predicate = lambda _: True))\n",
        "\n"
      ],
      "metadata": {
        "id": "hdsdvpsK_1oD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imprimindo o histórico\n"
      ],
      "metadata": {
        "id": "OiAubct0BFOS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for message in chat.history:\n",
        "  display(to_markdown(f'**{message.role}**: {message.parts[0].text}'))\n",
        "  print('--------------------------------------------')"
      ],
      "metadata": {
        "id": "kiHs7YN1BJSV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# enquanto não for encerrada a cessão a IA manterá o centexto dentro da variável criada lá em cima do código, no caso a variaável \"chat\" e para visualizar todo o contexto basta passar o comando:\n",
        "\n",
        "chat.history"
      ],
      "metadata": {
        "id": "67533HgKCVJY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}